# Reasoning under Ambiguity  
### Uncertainty-Aware Multilingual Emotion Classification under Partial Supervision

This repository contains the official implementation of **Reasoning under Ambiguity**, a framework for multilingual multi-label emotion classification that explicitly models annotation ambiguity under partial supervision.  
The method addresses the common but often overlooked assumption that missing emotion labels indicate negative evidence, which is not valid for real-world emotion datasets.

---

## ğŸ“Œ Key Idea

Emotion annotations are inherently **ambiguous**, **overlapping**, and often **incomplete**.  
Rather than treating unannotated labels as negatives, this work:

- Quantifies **annotation ambiguity** using entropy over observed labels  
- Applies **instance-level ambiguity weighting** during training  
- Supports **partial supervision** via masked losses  
- Achieves **stable and robust learning** across languages  

---

## âœ¨ Contributions

- **Ambiguity-aware learning objective** using entropy-based instance weighting  
- **Masked multi-label loss** that avoids penalizing missing annotations  
- Optional **positiveâ€“unlabeled (PU) regularization**  
- Extensive evaluation on **SemEval-2018 Task 1 (E-c)**  
- Analyses on stability, label-wise uncertainty, ambiguity stratification, and interpretability  

---

## ğŸŒ Datasets

We evaluate on **SemEval-2018 Task 1: Affect in Tweets (Emotion Classification)**:

| Language | Split | Instances |
|--------|------|-----------|
| English | train / dev / test | âœ“ |
| Spanish | train / dev / test | âœ“ |
| Arabic | train / dev / test | âœ“ |

Each instance may contain **multiple emotion labels**, drawn from a shared inventory of 11 emotions.

> Missing labels indicate *unknown*, not *negative* supervision.

---

## ğŸ§  Method Overview

For each training instance:

1. Encode text using a multilingual transformer (e.g., XLM-R)
2. Predict label probabilities
3. Compute entropy over **observed labels only**
4. Convert entropy into an **ambiguity weight**
5. Optimize a **masked, ambiguity-weighted BCE loss**
6. Optionally apply PU regularization to unobserved labels

See Algorithm 1 in the paper for full details.

## ğŸ“‚ Repository Structure
```
â”œâ”€â”€ train.py # Main training script
â”œâ”€â”€ multilingual_emotion_uncertainty_train.py
â”œâ”€â”€ modeling.py # Model definitions
â”œâ”€â”€ losses.py # Ambiguity-weighted + PU losses
â”œâ”€â”€ metrics.py # Evaluation metrics
â”œâ”€â”€ data_io.py # Dataset loading and masking
â”‚
â”œâ”€â”€ ablation.py # Ablation experiments
â”œâ”€â”€ training_stability.py # Stability across seeds
â”œâ”€â”€ eval_jaccard.py # Jaccard similarity evaluation
â”‚
â”œâ”€â”€ analysis_out/ # Analysis artifacts
â”‚ â”œâ”€â”€ dataset_stats/
â”‚ â”œâ”€â”€ label_uncertainty_.csv
â”‚ â”œâ”€â”€ ambiguity_vs_perf_.csv
â”‚ â”œâ”€â”€ nn_examples*.tex
â”‚
â”œâ”€â”€ runs/ # Saved checkpoints and metrics
â”œâ”€â”€ README.md
```
## ğŸš€ Training

### Example: English with ambiguity weighting

```
python train.py \
  --lang en \
  --uncertainty_mode ambiguity_weight \
  --encoder xlm-roberta-base \
  --epochs 10 \
  --batch_size 16
```
Multilingual training
```
python train.py \
  --lang both \
  --uncertainty_mode ambiguity_weight \
  --encoder xlm-roberta-base
```
ğŸ“Š Evaluation
Standard metrics
  1. Hamming Loss (HL)
  2. Ranking Loss (RL)
  3. Micro-F1
  4. Macro-F1
  5. Average Precision (AP)
  6. Jaccard Similarity
```
python eval_jaccard.py \
  --ckpt runs/en_es_ar_ambiguity/model.pt \
  --test_path Spanish/Spanish-E-c/test.txt \
  --lang es \
  --uncertainty_mode ambiguity_weight
```
ğŸ” Analysis and Interpretability
The repository includes scripts to reproduce:
  1. Ablation studies (baseline vs ambiguity vs evidential)
  2. Training stability across seeds
  3. Label-wise uncertainty analysis
  4. Ambiguity-stratified performance
  5. Nearest-neighbor explanations in embedding space
  6. Generated tables are exported directly to LaTeX for paper use.

ğŸ“ˆ Main Findings
  a. Ambiguity-weighted learning consistently improves macro-F1 and AP
  b. Training is more stable compared to evidential uncertainty methods
  c. Performance degrades smoothly with increasing ambiguity
  d. Learned embeddings support interpretable similarity-based explanations

ğŸ“„ Citation
If you use this work, please cite:
```
@inproceedings{mohammad2018semeval,
  title     = {SemEval-2018 Task 1: Affect in Tweets},
  author    = {Mohammad, Saif M. and Bravo-Marquez, Felipe and Salameh, Mohammad and Kiritchenko, Svetlana},
  booktitle = {Proceedings of the 12th International Workshop on Semantic Evaluation},
  year      = {2018}
}
```
âš ï¸ Notes
  This code assumes partial supervision by design
  Missing labels are never treated as negatives
  Results may differ if labels are artificially completed

ğŸ“¬ Contact
Md. Mithun Hossain
Research Assistant, BUBT Research Graduate School
ğŸ“§ mhosen751@gmail.com

â­ Acknowledgements
This work builds on prior research in multi-label learning, emotion analysis, and uncertainty-aware modeling. We thank the SemEval organizers for providing high-quality multilingual benchmarks.
